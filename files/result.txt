def @main(%input_ids: Tensor[(8, 512), int64] /* ty=Tensor[(8, 512), int64] span=/bert/embeddings/word_embeddings/Gather.input_ids:0:0 */, %bert.embeddings.word_embeddings.weight: Tensor[(30522, 768), float32] /* ty=Tensor[(30522, 768), float32] span=/bert/embeddings/word_embeddings/Gather.bert.embeddings.word_embeddings.weight:0:0 */, %bert.embeddings.position_embeddings.weight: Tensor[(512, 768), float32] /* ty=Tensor[(512, 768), float32] span=/bert/embeddings/position_embeddings/Gather.bert.embeddings.position_embeddings.weight:0:0 */, %bert.embeddings.token_type_embeddings.weight: Tensor[(2, 768), float32] /* ty=Tensor[(2, 768), float32] span=/bert/embeddings/token_type_embeddings/Gather.bert.embeddings.token_type_embeddings.weight:0:0 */, %bert.embeddings.LayerNorm.weight: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/embeddings/LayerNorm/LayerNormalization.bert.embeddings.LayerNorm.weight:0:0 */, %bert.embeddings.LayerNorm.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/embeddings/LayerNorm/LayerNormalization.bert.embeddings.LayerNorm.bias:0:0 */, %bert.encoder.layer.0.attention.self.query.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.0/attention/self/query/Add.bert.encoder.layer.0.attention.self.query.bias:0:0 */, %bert.encoder.layer.0.attention.self.key.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.0/attention/self/key/Add.bert.encoder.layer.0.attention.self.key.bias:0:0 */, %bert.encoder.layer.0.attention.self.value.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.0/attention/self/value/Add.bert.encoder.layer.0.attention.self.value.bias:0:0 */, %bert.encoder.layer.0.attention.output.dense.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.0/attention/output/dense/Add.bert.encoder.layer.0.attention.output.dense.bias:0:0 */, %bert.encoder.layer.0.attention.output.LayerNorm.weight: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.0/attention/output/LayerNorm/LayerNormalization.bert.encoder.layer.0.attention.output.LayerNorm.weight:0:0 */, %bert.encoder.layer.0.attention.output.LayerNorm.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.0/attention/output/LayerNorm/LayerNormalization.bert.encoder.layer.0.attention.output.LayerNorm.bias:0:0 */, %bert.encoder.layer.0.intermediate.dense.bias: Tensor[(3072), float32] /* ty=Tensor[(3072), float32] span=/bert/encoder/layer.0/intermediate/dense/Add.bert.encoder.layer.0.intermediate.dense.bias:0:0 */, %bert.encoder.layer.0.output.dense.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.0/output/dense/Add.bert.encoder.layer.0.output.dense.bias:0:0 */, %bert.encoder.layer.0.output.LayerNorm.weight: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.0/output/LayerNorm/LayerNormalization.bert.encoder.layer.0.output.LayerNorm.weight:0:0 */, %bert.encoder.layer.0.output.LayerNorm.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.0/output/LayerNorm/LayerNormalization.bert.encoder.layer.0.output.LayerNorm.bias:0:0 */, %bert.encoder.layer.1.attention.self.query.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.1/attention/self/query/Add.bert.encoder.layer.1.attention.self.query.bias:0:0 */, %bert.encoder.layer.1.attention.self.key.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.1/attention/self/key/Add.bert.encoder.layer.1.attention.self.key.bias:0:0 */, %bert.encoder.layer.1.attention.self.value.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.1/attention/self/value/Add.bert.encoder.layer.1.attention.self.value.bias:0:0 */, %bert.encoder.layer.1.attention.output.dense.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.1/attention/output/dense/Add.bert.encoder.layer.1.attention.output.dense.bias:0:0 */, %bert.encoder.layer.1.attention.output.LayerNorm.weight: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.1/attention/output/LayerNorm/LayerNormalization.bert.encoder.layer.1.attention.output.LayerNorm.weight:0:0 */, %bert.encoder.layer.1.attention.output.LayerNorm.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.1/attention/output/LayerNorm/LayerNormalization.bert.encoder.layer.1.attention.output.LayerNorm.bias:0:0 */, %bert.encoder.layer.1.intermediate.dense.bias: Tensor[(3072), float32] /* ty=Tensor[(3072), float32] span=/bert/encoder/layer.1/intermediate/dense/Add.bert.encoder.layer.1.intermediate.dense.bias:0:0 */, %bert.encoder.layer.1.output.dense.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.1/output/dense/Add.bert.encoder.layer.1.output.dense.bias:0:0 */, %bert.encoder.layer.1.output.LayerNorm.weight: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.1/output/LayerNorm/LayerNormalization.bert.encoder.layer.1.output.LayerNorm.weight:0:0 */, %bert.encoder.layer.1.output.LayerNorm.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.1/output/LayerNorm/LayerNormalization.bert.encoder.layer.1.output.LayerNorm.bias:0:0 */, %bert.encoder.layer.2.attention.self.query.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.2/attention/self/query/Add.bert.encoder.layer.2.attention.self.query.bias:0:0 */, %bert.encoder.layer.2.attention.self.key.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.2/attention/self/key/Add.bert.encoder.layer.2.attention.self.key.bias:0:0 */, %bert.encoder.layer.2.attention.self.value.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.2/attention/self/value/Add.bert.encoder.layer.2.attention.self.value.bias:0:0 */, %bert.encoder.layer.2.attention.output.dense.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.2/attention/output/dense/Add.bert.encoder.layer.2.attention.output.dense.bias:0:0 */, %bert.encoder.layer.2.attention.output.LayerNorm.weight: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.2/attention/output/LayerNorm/LayerNormalization.bert.encoder.layer.2.attention.output.LayerNorm.weight:0:0 */, %bert.encoder.layer.2.attention.output.LayerNorm.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.2/attention/output/LayerNorm/LayerNormalization.bert.encoder.layer.2.attention.output.LayerNorm.bias:0:0 */, %bert.encoder.layer.2.intermediate.dense.bias: Tensor[(3072), float32] /* ty=Tensor[(3072), float32] span=/bert/encoder/layer.2/intermediate/dense/Add.bert.encoder.layer.2.intermediate.dense.bias:0:0 */, %bert.encoder.layer.2.output.dense.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.2/output/dense/Add.bert.encoder.layer.2.output.dense.bias:0:0 */, %bert.encoder.layer.2.output.LayerNorm.weight: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.2/output/LayerNorm/LayerNormalization.bert.encoder.layer.2.output.LayerNorm.weight:0:0 */, %bert.encoder.layer.2.output.LayerNorm.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.2/output/LayerNorm/LayerNormalization.bert.encoder.layer.2.output.LayerNorm.bias:0:0 */, %bert.encoder.layer.3.attention.self.query.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.3/attention/self/query/Add.bert.encoder.layer.3.attention.self.query.bias:0:0 */, %bert.encoder.layer.3.attention.self.key.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.3/attention/self/key/Add.bert.encoder.layer.3.attention.self.key.bias:0:0 */, %bert.encoder.layer.3.attention.self.value.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.3/attention/self/value/Add.bert.encoder.layer.3.attention.self.value.bias:0:0 */, %bert.encoder.layer.3.attention.output.dense.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.3/attention/output/dense/Add.bert.encoder.layer.3.attention.output.dense.bias:0:0 */, %bert.encoder.layer.3.attention.output.LayerNorm.weight: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.3/attention/output/LayerNorm/LayerNormalization.bert.encoder.layer.3.attention.output.LayerNorm.weight:0:0 */, %bert.encoder.layer.3.attention.output.LayerNorm.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.3/attention/output/LayerNorm/LayerNormalization.bert.encoder.layer.3.attention.output.LayerNorm.bias:0:0 */, %bert.encoder.layer.3.intermediate.dense.bias: Tensor[(3072), float32] /* ty=Tensor[(3072), float32] span=/bert/encoder/layer.3/intermediate/dense/Add.bert.encoder.layer.3.intermediate.dense.bias:0:0 */, %bert.encoder.layer.3.output.dense.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.3/output/dense/Add.bert.encoder.layer.3.output.dense.bias:0:0 */, %bert.encoder.layer.3.output.LayerNorm.weight: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.3/output/LayerNorm/LayerNormalization.bert.encoder.layer.3.output.LayerNorm.weight:0:0 */, %bert.encoder.layer.3.output.LayerNorm.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.3/output/LayerNorm/LayerNormalization.bert.encoder.layer.3.output.LayerNorm.bias:0:0 */, %bert.encoder.layer.4.attention.self.query.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.4/attention/self/query/Add.bert.encoder.layer.4.attention.self.query.bias:0:0 */, %bert.encoder.layer.4.attention.self.key.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.4/attention/self/key/Add.bert.encoder.layer.4.attention.self.key.bias:0:0 */, %bert.encoder.layer.4.attention.self.value.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.4/attention/self/value/Add.bert.encoder.layer.4.attention.self.value.bias:0:0 */, %bert.encoder.layer.4.attention.output.dense.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.4/attention/output/dense/Add.bert.encoder.layer.4.attention.output.dense.bias:0:0 */, %bert.encoder.layer.4.attention.output.LayerNorm.weight: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.4/attention/output/LayerNorm/LayerNormalization.bert.encoder.layer.4.attention.output.LayerNorm.weight:0:0 */, %bert.encoder.layer.4.attention.output.LayerNorm.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.4/attention/output/LayerNorm/LayerNormalization.bert.encoder.layer.4.attention.output.LayerNorm.bias:0:0 */, %bert.encoder.layer.4.intermediate.dense.bias: Tensor[(3072), float32] /* ty=Tensor[(3072), float32] span=/bert/encoder/layer.4/intermediate/dense/Add.bert.encoder.layer.4.intermediate.dense.bias:0:0 */, %bert.encoder.layer.4.output.dense.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.4/output/dense/Add.bert.encoder.layer.4.output.dense.bias:0:0 */, %bert.encoder.layer.4.output.LayerNorm.weight: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.4/output/LayerNorm/LayerNormalization.bert.encoder.layer.4.output.LayerNorm.weight:0:0 */, %bert.encoder.layer.4.output.LayerNorm.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.4/output/LayerNorm/LayerNormalization.bert.encoder.layer.4.output.LayerNorm.bias:0:0 */, %bert.encoder.layer.5.attention.self.query.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.5/attention/self/query/Add.bert.encoder.layer.5.attention.self.query.bias:0:0 */, %bert.encoder.layer.5.attention.self.key.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.5/attention/self/key/Add.bert.encoder.layer.5.attention.self.key.bias:0:0 */, %bert.encoder.layer.5.attention.self.value.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.5/attention/self/value/Add.bert.encoder.layer.5.attention.self.value.bias:0:0 */, %bert.encoder.layer.5.attention.output.dense.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.5/attention/output/dense/Add.bert.encoder.layer.5.attention.output.dense.bias:0:0 */, %bert.encoder.layer.5.attention.output.LayerNorm.weight: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.5/attention/output/LayerNorm/LayerNormalization.bert.encoder.layer.5.attention.output.LayerNorm.weight:0:0 */, %bert.encoder.layer.5.attention.output.LayerNorm.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.5/attention/output/LayerNorm/LayerNormalization.bert.encoder.layer.5.attention.output.LayerNorm.bias:0:0 */, %bert.encoder.layer.5.intermediate.dense.bias: Tensor[(3072), float32] /* ty=Tensor[(3072), float32] span=/bert/encoder/layer.5/intermediate/dense/Add.bert.encoder.layer.5.intermediate.dense.bias:0:0 */, %bert.encoder.layer.5.output.dense.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.5/output/dense/Add.bert.encoder.layer.5.output.dense.bias:0:0 */, %bert.encoder.layer.5.output.LayerNorm.weight: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.5/output/LayerNorm/LayerNormalization.bert.encoder.layer.5.output.LayerNorm.weight:0:0 */, %bert.encoder.layer.5.output.LayerNorm.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.5/output/LayerNorm/LayerNormalization.bert.encoder.layer.5.output.LayerNorm.bias:0:0 */, %bert.encoder.layer.6.attention.self.query.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.6/attention/self/query/Add.bert.encoder.layer.6.attention.self.query.bias:0:0 */, %bert.encoder.layer.6.attention.self.key.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.6/attention/self/key/Add.bert.encoder.layer.6.attention.self.key.bias:0:0 */, %bert.encoder.layer.6.attention.self.value.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.6/attention/self/value/Add.bert.encoder.layer.6.attention.self.value.bias:0:0 */, %bert.encoder.layer.6.attention.output.dense.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.6/attention/output/dense/Add.bert.encoder.layer.6.attention.output.dense.bias:0:0 */, %bert.encoder.layer.6.attention.output.LayerNorm.weight: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.6/attention/output/LayerNorm/LayerNormalization.bert.encoder.layer.6.attention.output.LayerNorm.weight:0:0 */, %bert.encoder.layer.6.attention.output.LayerNorm.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.6/attention/output/LayerNorm/LayerNormalization.bert.encoder.layer.6.attention.output.LayerNorm.bias:0:0 */, %bert.encoder.layer.6.intermediate.dense.bias: Tensor[(3072), float32] /* ty=Tensor[(3072), float32] span=/bert/encoder/layer.6/intermediate/dense/Add.bert.encoder.layer.6.intermediate.dense.bias:0:0 */, %bert.encoder.layer.6.output.dense.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.6/output/dense/Add.bert.encoder.layer.6.output.dense.bias:0:0 */, %bert.encoder.layer.6.output.LayerNorm.weight: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.6/output/LayerNorm/LayerNormalization.bert.encoder.layer.6.output.LayerNorm.weight:0:0 */, %bert.encoder.layer.6.output.LayerNorm.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.6/output/LayerNorm/LayerNormalization.bert.encoder.layer.6.output.LayerNorm.bias:0:0 */, %bert.encoder.layer.7.attention.self.query.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.7/attention/self/query/Add.bert.encoder.layer.7.attention.self.query.bias:0:0 */, %bert.encoder.layer.7.attention.self.key.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.7/attention/self/key/Add.bert.encoder.layer.7.attention.self.key.bias:0:0 */, %bert.encoder.layer.7.attention.self.value.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.7/attention/self/value/Add.bert.encoder.layer.7.attention.self.value.bias:0:0 */, %bert.encoder.layer.7.attention.output.dense.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.7/attention/output/dense/Add.bert.encoder.layer.7.attention.output.dense.bias:0:0 */, %bert.encoder.layer.7.attention.output.LayerNorm.weight: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.7/attention/output/LayerNorm/LayerNormalization.bert.encoder.layer.7.attention.output.LayerNorm.weight:0:0 */, %bert.encoder.layer.7.attention.output.LayerNorm.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.7/attention/output/LayerNorm/LayerNormalization.bert.encoder.layer.7.attention.output.LayerNorm.bias:0:0 */, %bert.encoder.layer.7.intermediate.dense.bias: Tensor[(3072), float32] /* ty=Tensor[(3072), float32] span=/bert/encoder/layer.7/intermediate/dense/Add.bert.encoder.layer.7.intermediate.dense.bias:0:0 */, %bert.encoder.layer.7.output.dense.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.7/output/dense/Add.bert.encoder.layer.7.output.dense.bias:0:0 */, %bert.encoder.layer.7.output.LayerNorm.weight: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.7/output/LayerNorm/LayerNormalization.bert.encoder.layer.7.output.LayerNorm.weight:0:0 */, %bert.encoder.layer.7.output.LayerNorm.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.7/output/LayerNorm/LayerNormalization.bert.encoder.layer.7.output.LayerNorm.bias:0:0 */, %bert.encoder.layer.8.attention.self.query.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.8/attention/self/query/Add.bert.encoder.layer.8.attention.self.query.bias:0:0 */, %bert.encoder.layer.8.attention.self.key.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.8/attention/self/key/Add.bert.encoder.layer.8.attention.self.key.bias:0:0 */, %bert.encoder.layer.8.attention.self.value.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.8/attention/self/value/Add.bert.encoder.layer.8.attention.self.value.bias:0:0 */, %bert.encoder.layer.8.attention.output.dense.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.8/attention/output/dense/Add.bert.encoder.layer.8.attention.output.dense.bias:0:0 */, %bert.encoder.layer.8.attention.output.LayerNorm.weight: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.8/attention/output/LayerNorm/LayerNormalization.bert.encoder.layer.8.attention.output.LayerNorm.weight:0:0 */, %bert.encoder.layer.8.attention.output.LayerNorm.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.8/attention/output/LayerNorm/LayerNormalization.bert.encoder.layer.8.attention.output.LayerNorm.bias:0:0 */, %bert.encoder.layer.8.intermediate.dense.bias: Tensor[(3072), float32] /* ty=Tensor[(3072), float32] span=/bert/encoder/layer.8/intermediate/dense/Add.bert.encoder.layer.8.intermediate.dense.bias:0:0 */, %bert.encoder.layer.8.output.dense.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.8/output/dense/Add.bert.encoder.layer.8.output.dense.bias:0:0 */, %bert.encoder.layer.8.output.LayerNorm.weight: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.8/output/LayerNorm/LayerNormalization.bert.encoder.layer.8.output.LayerNorm.weight:0:0 */, %bert.encoder.layer.8.output.LayerNorm.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.8/output/LayerNorm/LayerNormalization.bert.encoder.layer.8.output.LayerNorm.bias:0:0 */, %bert.encoder.layer.9.attention.self.query.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.9/attention/self/query/Add.bert.encoder.layer.9.attention.self.query.bias:0:0 */, %bert.encoder.layer.9.attention.self.key.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.9/attention/self/key/Add.bert.encoder.layer.9.attention.self.key.bias:0:0 */, %bert.encoder.layer.9.attention.self.value.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.9/attention/self/value/Add.bert.encoder.layer.9.attention.self.value.bias:0:0 */, %bert.encoder.layer.9.attention.output.dense.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.9/attention/output/dense/Add.bert.encoder.layer.9.attention.output.dense.bias:0:0 */, %bert.encoder.layer.9.attention.output.LayerNorm.weight: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.9/attention/output/LayerNorm/LayerNormalization.bert.encoder.layer.9.attention.output.LayerNorm.weight:0:0 */, %bert.encoder.layer.9.attention.output.LayerNorm.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.9/attention/output/LayerNorm/LayerNormalization.bert.encoder.layer.9.attention.output.LayerNorm.bias:0:0 */, %bert.encoder.layer.9.intermediate.dense.bias: Tensor[(3072), float32] /* ty=Tensor[(3072), float32] span=/bert/encoder/layer.9/intermediate/dense/Add.bert.encoder.layer.9.intermediate.dense.bias:0:0 */, %bert.encoder.layer.9.output.dense.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.9/output/dense/Add.bert.encoder.layer.9.output.dense.bias:0:0 */, %bert.encoder.layer.9.output.LayerNorm.weight: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.9/output/LayerNorm/LayerNormalization.bert.encoder.layer.9.output.LayerNorm.weight:0:0 */, %bert.encoder.layer.9.output.LayerNorm.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.9/output/LayerNorm/LayerNormalization.bert.encoder.layer.9.output.LayerNorm.bias:0:0 */, %bert.encoder.layer.10.attention.self.query.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.10/attention/self/query/Add.bert.encoder.layer.10.attention.self.query.bias:0:0 */, %bert.encoder.layer.10.attention.self.key.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.10/attention/self/key/Add.bert.encoder.layer.10.attention.self.key.bias:0:0 */, %bert.encoder.layer.10.attention.self.value.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.10/attention/self/value/Add.bert.encoder.layer.10.attention.self.value.bias:0:0 */, %bert.encoder.layer.10.attention.output.dense.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.10/attention/output/dense/Add.bert.encoder.layer.10.attention.output.dense.bias:0:0 */, %bert.encoder.layer.10.attention.output.LayerNorm.weight: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.10/attention/output/LayerNorm/LayerNormalization.bert.encoder.layer.10.attention.output.LayerNorm.weight:0:0 */, %bert.encoder.layer.10.attention.output.LayerNorm.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.10/attention/output/LayerNorm/LayerNormalization.bert.encoder.layer.10.attention.output.LayerNorm.bias:0:0 */, %bert.encoder.layer.10.intermediate.dense.bias: Tensor[(3072), float32] /* ty=Tensor[(3072), float32] span=/bert/encoder/layer.10/intermediate/dense/Add.bert.encoder.layer.10.intermediate.dense.bias:0:0 */, %bert.encoder.layer.10.output.dense.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.10/output/dense/Add.bert.encoder.layer.10.output.dense.bias:0:0 */, %bert.encoder.layer.10.output.LayerNorm.weight: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.10/output/LayerNorm/LayerNormalization.bert.encoder.layer.10.output.LayerNorm.weight:0:0 */, %bert.encoder.layer.10.output.LayerNorm.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.10/output/LayerNorm/LayerNormalization.bert.encoder.layer.10.output.LayerNorm.bias:0:0 */, %bert.encoder.layer.11.attention.self.query.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.11/attention/self/query/Add.bert.encoder.layer.11.attention.self.query.bias:0:0 */, %bert.encoder.layer.11.attention.self.key.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.11/attention/self/key/Add.bert.encoder.layer.11.attention.self.key.bias:0:0 */, %bert.encoder.layer.11.attention.self.value.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.11/attention/self/value/Add.bert.encoder.layer.11.attention.self.value.bias:0:0 */, %bert.encoder.layer.11.attention.output.dense.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.11/attention/output/dense/Add.bert.encoder.layer.11.attention.output.dense.bias:0:0 */, %bert.encoder.layer.11.attention.output.LayerNorm.weight: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.11/attention/output/LayerNorm/LayerNormalization.bert.encoder.layer.11.attention.output.LayerNorm.weight:0:0 */, %bert.encoder.layer.11.attention.output.LayerNorm.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.11/attention/output/LayerNorm/LayerNormalization.bert.encoder.layer.11.attention.output.LayerNorm.bias:0:0 */, %bert.encoder.layer.11.intermediate.dense.bias: Tensor[(3072), float32] /* ty=Tensor[(3072), float32] span=/bert/encoder/layer.11/intermediate/dense/Add.bert.encoder.layer.11.intermediate.dense.bias:0:0 */, %bert.encoder.layer.11.output.dense.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.11/output/dense/Add.bert.encoder.layer.11.output.dense.bias:0:0 */, %bert.encoder.layer.11.output.LayerNorm.weight: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.11/output/LayerNorm/LayerNormalization.bert.encoder.layer.11.output.LayerNorm.weight:0:0 */, %bert.encoder.layer.11.output.LayerNorm.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/bert/encoder/layer.11/output/LayerNorm/LayerNormalization.bert.encoder.layer.11.output.LayerNorm.bias:0:0 */, %cls.predictions.bias: Tensor[(30522), float32] /* ty=Tensor[(30522), float32] span=/cls/predictions/decoder/Add.cls.predictions.bias:0:0 */, %cls.predictions.transform.dense.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/cls/predictions/transform/dense/Add.cls.predictions.transform.dense.bias:0:0 */, %cls.predictions.transform.LayerNorm.weight: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/cls/predictions/transform/LayerNorm/LayerNormalization.cls.predictions.transform.LayerNorm.weight:0:0 */, %cls.predictions.transform.LayerNorm.bias: Tensor[(768), float32] /* ty=Tensor[(768), float32] span=/cls/predictions/transform/LayerNorm/LayerNormalization.cls.predictions.transform.LayerNorm.bias:0:0 */, %onnx::MatMul_1450: Tensor[(768, 768), float32] /* ty=Tensor[(768, 768), float32] span=/bert/encoder/layer.0/attention/self/query/MatMul.onnx::MatMul_1450:0:0 */, %onnx::MatMul_1456: Tensor[(768, 768), float32] /* ty=Tensor[(768, 768), float32] span=/bert/encoder/layer.0/attention/self/key/MatMul.onnx::MatMul_1456:0:0 */, %onnx::MatMul_1462: Tensor[(768, 768), float32] /* ty=Tensor[(768, 768), float32] span=/bert/encoder/layer.0/attention/self/value/MatMul.onnx::MatMul_1462:0:0 */, %onnx::MatMul_1472: Tensor[(768, 768), float32] /* ty=Tensor[(768, 768), float32] span=/bert/encoder/layer.0/attention/output/dense/MatMul.onnx::MatMul_1472:0:0 */, %onnx::MatMul_1473: Tensor[(768, 3072), float32] /* ty=Tensor[(768, 3072), float32] span=/bert/encoder/layer.0/intermediate/dense/MatMul.onnx::MatMul_1473:0:0 */, %onnx::MatMul_1474: Tensor[(3072, 768), float32] /* ty=Tensor[(3072, 768), float32] span=/bert/encoder/layer.0/output/dense/MatMul.onnx::MatMul_1474:0:0 */, %onnx::MatMul_1475: Tensor[(768, 768), float32] /* ty=Tensor[(768, 768), float32] span=/bert/encoder/layer.1/attention/self/query/MatMul.onnx::MatMul_1475:0:0 */, %onnx::MatMul_1481: Tensor[(768, 768), float32] /* ty=Tensor[(768, 768), float32] span=/bert/encoder/layer.1/attention/self/key/MatMul.onnx::MatMul_1481:0:0 */, %onnx::MatMul_1487: Tensor[(768, 768), float32] /* ty=Tensor[(768, 768), float32] span=/bert/encoder/layer.1/attention/self/value/MatMul.onnx::MatMul_1487:0:0 */, %onnx::MatMul_1497: Tensor[(768, 768), float32] /* ty=Tensor[(768, 768), float32] span=/bert/encoder/layer.1/attention/output/dense/MatMul.onnx::MatMul_1497:0:0 */, %onnx::MatMul_1498: Tensor[(768, 3072), float32] /* ty=Tensor[(768, 3072), float32] span=/bert/encoder/layer.1/intermediate/dense/MatMul.onnx::MatMul_1498:0:0 */, %onnx::MatMul_1499: Tensor[(3072, 768), float32] /* ty=Tensor[(3072, 768), float32] span=/bert/encoder/layer.1/output/dense/MatMul.onnx::MatMul_1499:0:0 */, %onnx::MatMul_1500: Tensor[(768, 768), float32] /* ty=Tensor[(768, 768), float32] span=/bert/encoder/layer.2/attention/self/query/MatMul.onnx::MatMul_1500:0:0 */, %onnx::MatMul_1506: Tensor[(768, 768), float32] /* ty=Tensor[(768, 768), float32] span=/bert/encoder/layer.2/attention/self/key/MatMul.onnx::MatMul_1506:0:0 */, %onnx::MatMul_1512: Tensor[(768, 768), float32] /* ty=Tensor[(768, 768), float32] span=/bert/encoder/layer.2/attention/self/value/MatMul.onnx::MatMul_1512:0:0 */, %onnx::MatMul_1522: Tensor[(768, 768), float32] /* ty=Tensor[(768, 768), float32] span=/bert/encoder/layer.2/attention/output/dense/MatMul.onnx::MatMul_1522:0:0 */, %onnx::MatMul_1523: Tensor[(768, 3072), float32] /* ty=Tensor[(768, 3072), float32] span=/bert/encoder/layer.2/intermediate/dense/MatMul.onnx::MatMul_1523:0:0 */, %onnx::MatMul_1524: Tensor[(3072, 768), float32] /* ty=Tensor[(3072, 768), float32] span=/bert/encoder/layer.2/output/dense/MatMul.onnx::MatMul_1524:0:0 */, %onnx::MatMul_1525: Tensor[(768, 768), float32] /* ty=Tensor[(768, 768), float32] span=/bert/encoder/layer.3/attention/self/query/MatMul.onnx::MatMul_1525:0:0 */, %onnx::MatMul_1531: Tensor[(768, 768), float32] /* ty=Tensor[(768, 768), float32] span=/bert/encoder/layer.3/attention/self/key/MatMul.onnx::MatMul_1531:0:0 */, %onnx::MatMul_1537: Tensor[(768, 768), float32] /* ty=Tensor[(768, 768), float32] span=/bert/encoder/layer.3/attention/self/value/MatMul.onnx::MatMul_1537:0:0 */, %onnx::MatMul_1547: Tensor[(768, 768), float32] /* ty=Tensor[(768, 768), float32] span=/bert/encoder/layer.3/attention/output/dense/MatMul.onnx::MatMul_1547:0:0 */, %onnx::MatMul_1548: Tensor[(768, 3072), float32] /* ty=Tensor[(768, 3072), float32] span=/bert/encoder/layer.3/intermediate/dense/MatMul.onnx::MatMul_1548:0:0 */, %onnx::MatMul_1549: Tensor[(3072, 768), float32] /* ty=Tensor[(3072, 768), float32] span=/bert/encoder/layer.3/output/dense/MatMul.onnx::MatMul_1549:0:0 */, %onnx::MatMul_1550: Tensor[(768, 768), float32] /* ty=Tensor[(768, 768), float32] span=/bert/encoder/layer.4/attention/self/query/MatMul.onnx::MatMul_1550:0:0 */, %onnx::MatMul_1556: Tensor[(768, 768), float32] /* ty=Tensor[(768, 768), float32] span=/bert/encoder/layer.4/attention/self/key/MatMul.onnx::MatMul_1556:0:0 */, %onnx::MatMul_1562: Tensor[(768, 768), float32] /* ty=Tensor[(768, 768), float32] span=/bert/encoder/layer.4/attention/self/value/MatMul.onnx::MatMul_1562:0:0 */, %onnx::MatMul_1572: Tensor[(768, 768), float32] /* ty=Tensor[(768, 768), float32] span=/bert/encoder/layer.4/attention/output/dense/MatMul.onnx::MatMul_1572:0:0 */, %onnx::MatMul_1573: Tensor[(768, 3072), float32] /* ty=Tensor[(768, 3072), float32] span=/bert/encoder/layer.4/intermediate/dense/MatMul.onnx::MatMul_1573:0:0 */, %onnx::MatMul_1574: Tensor[(3072, 768), float32] /* ty=Tensor[(3072, 768), float32] span=/bert/encoder/layer.4/output/dense/MatMul.onnx::MatMul_1574:0:0 */, %onnx::MatMul_1575: Tensor[(768, 768), float32] /* ty=Tensor[(768, 768), float32] span=/bert/encoder/layer.5/attention/self/query/MatMul.onnx::MatMul_1575:0:0 */, %onnx::MatMul_1581: Tensor[(768, 768), float32] /* ty=Tensor[(768, 768), float32] span=/bert/encoder/layer.5/attention/self/key/MatMul.onnx::MatMul_1581:0:0 */, %onnx::MatMul_1587: Tensor[(768, 768), float32] /* ty=Tensor[(768, 768), float32] span=/bert/encoder/layer.5/attention/self/value/MatMul.onnx::MatMul_1587:0:0 */, %onnx::MatMul_1597: Tensor[(768, 768), float32] /* ty=Tensor[(768, 768), float32] span=/bert/encoder/layer.5/attention/output/dense/MatMul.onnx::MatMul_1597:0:0 */, %onnx::MatMul_1598: Tensor[(768, 3072), float32] /* ty=Tensor[(768, 3072), float32] span=/bert/encoder/layer.5/intermediate/dense/MatMul.onnx::MatMul_1598:0:0 */, %onnx::MatMul_1599: Tensor[(3072, 768), float32] /* ty=Tensor[(3072, 768), float32] span=/bert/encoder/layer.5/output/dense/MatMul.onnx::MatMul_1599:0:0 */, %onnx::MatMul_1600: Tensor[(768, 768), float32] /* ty=Tensor[(768, 768), float32] span=/bert/encoder/layer.6/attention/self/query/MatMul.onnx::MatMul_1600:0:0 */, %onnx::MatMul_1606: Tensor[(768, 768), float32] /* ty=Tensor[(768, 768), float32] span=/bert/encoder/layer.6/attention/self/key/MatMul.onnx::MatMul_1606:0:0 */, %onnx::MatMul_1612: Tensor[(768, 768), float32] /* ty=Tensor[(768, 768), float32] span=/bert/encoder/layer.6/attention/self/value/MatMul.onnx::MatMul_1612:0:0 */, %onnx::MatMul_1622: Tensor[(768, 768), float32] /* ty=Tensor[(768, 768), float32] span=/bert/encoder/layer.6/attention/output/dense/MatMul.onnx::MatMul_1622:0:0 */, %onnx::MatMul_1623: Tensor[(768, 3072), float32] /* ty=Tensor[(768, 3072), float32] span=/bert/encoder/layer.6/intermediate/dense/MatMul.onnx::MatMul_1623:0:0 */, %onnx::MatMul_1624: Tensor[(3072, 768), float32] /* ty=Tensor[(3072, 768), float32] span=/bert/encoder/layer.6/output/dense/MatMul.onnx::MatMul_1624:0:0 */, %onnx::MatMul_1625: Tensor[(768, 768), float32] /* ty=Tensor[(768, 768), float32] span=/bert/encoder/layer.7/attention/self/query/MatMul.onnx::MatMul_1625:0:0 */, %onnx::MatMul_1631: Tensor[(768, 768), float32] /* ty=Tensor[(768, 768), float32] span=/bert/encoder/layer.7/attention/self/key/MatMul.onnx::MatMul_1631:0:0 */, %onnx::MatMul_1637: Tensor[(768, 768), float32] /* ty=Tensor[(768, 768), float32] span=/bert/encoder/layer.7/attention/self/value/MatMul.onnx::MatMul_1637:0:0 */, %onnx::MatMul_1647: Tensor[(768, 768), float32] /* ty=Tensor[(768, 768), float32] span=/bert/encoder/layer.7/attention/output/dense/MatMul.onnx::MatMul_1647:0:0 */, %onnx::MatMul_1648: Tensor[(768, 3072), float32] /* ty=Tensor[(768, 3072), float32] span=/bert/encoder/layer.7/intermediate/dense/MatMul.onnx::MatMul_1648:0:0 */, %onnx::MatMul_1649: Tensor[(3072, 768), float32] /* ty=Tensor[(3072, 768), float32] span=/bert/encoder/layer.7/output/dense/MatMul.onnx::MatMul_1649:0:0 */, %onnx::MatMul_1650: Tensor[(768, 768), float32] /* ty=Tensor[(768, 768), float32] span=/bert/encoder/layer.8/attention/self/query/MatMul.onnx::MatMul_1650:0:0 */, %onnx::MatMul_1656: Tensor[(768, 768), float32] /* ty=Tensor[(768, 768), float32] span=/bert/encoder/layer.8/attention/self/key/MatMul.onnx::MatMul_1656:0:0 */, %onnx::MatMul_1662: Tensor[(768, 768), float32] /* ty=Tensor[(768, 768), float32] span=/bert/encoder/layer.8/attention/self/value/MatMul.onnx::MatMul_1662:0:0 */, %onnx::MatMul_1672: Tensor[(768, 768), float32] /* ty=Tensor[(768, 768), float32] span=/bert/encoder/layer.8/attention/output/dense/MatMul.onnx::MatMul_1672:0:0 */, %onnx::MatMul_1673: Tensor[(768, 3072), float32] /* ty=Tensor[(768, 3072), float32] span=/bert/encoder/layer.8/intermediate/dense/MatMul.onnx::MatMul_1673:0:0 */, %onnx::MatMul_1674: Tensor[(3072, 768), float32] /* ty=Tensor[(3072, 768), float32] span=/bert/encoder/layer.8/output/dense/MatMul.onnx::MatMul_1674:0:0 */, %onnx::MatMul_1675: Tensor[(768, 768), float32] /* ty=Tensor[(768, 768), float32] span=/bert/encoder/layer.9/attention/self/query/MatMul.onnx::MatMul_1675:0:0 */, %onnx::MatMul_1681: Tensor[(768, 768), float32] /* ty=Tensor[(768, 768), float32] span=/bert/encoder/layer.9/attention/self/key/MatMul.onnx::MatMul_1681:0:0 */, %onnx::MatMul_1687: Tensor[(768, 768), float32] /* ty=Tensor[(768, 768), float32] span=/bert/encoder/layer.9/attention/self/value/MatMul.onnx::MatMul_1687:0:0 */, %onnx::MatMul_1697: Tensor[(768, 768), float32] /* ty=Tensor[(768, 768), float32] span=/bert/encoder/layer.9/attention/output/dense/MatMul.onnx::MatMul_1697:0:0 */, %onnx::MatMul_1698: Tensor[(768, 3072), float32] /* ty=Tensor[(768, 3072), float32] span=/bert/encoder/layer.9/intermediate/dense/MatMul.onnx::MatMul_1698:0:0 */, %onnx::MatMul_1699: Tensor[(3072, 768), float32] /* ty=Tensor[(3072, 768), float32] span=/bert/encoder/layer.9/output/dense/MatMul.onnx::MatMul_1699:0:0 */, %onnx::MatMul_1700: Tensor[(768, 768), float32] /* ty=Tensor[(768, 768), float32] span=/bert/encoder/layer.10/attention/self/query/MatMul.onnx::MatMul_1700:0:0 */, %onnx::MatMul_1706: Tensor[(768, 768), float32] /* ty=Tensor[(768, 768), float32] span=/bert/encoder/layer.10/attention/self/key/MatMul.onnx::MatMul_1706:0:0 */, %onnx::MatMul_1712: Tensor[(768, 768), float32] /* ty=Tensor[(768, 768), float32] span=/bert/encoder/layer.10/attention/self/value/MatMul.onnx::MatMul_1712:0:0 */, %onnx::MatMul_1722: Tensor[(768, 768), float32] /* ty=Tensor[(768, 768), float32] span=/bert/encoder/layer.10/attention/output/dense/MatMul.onnx::MatMul_1722:0:0 */, %onnx::MatMul_1723: Tensor[(768, 3072), float32] /* ty=Tensor[(768, 3072), float32] span=/bert/encoder/layer.10/intermediate/dense/MatMul.onnx::MatMul_1723:0:0 */, %onnx::MatMul_1724: Tensor[(3072, 768), float32] /* ty=Tensor[(3072, 768), float32] span=/bert/encoder/layer.10/output/dense/MatMul.onnx::MatMul_1724:0:0 */, %onnx::MatMul_1725: Tensor[(768, 768), float32] /* ty=Tensor[(768, 768), float32] span=/bert/encoder/layer.11/attention/self/query/MatMul.onnx::MatMul_1725:0:0 */, %onnx::MatMul_1731: Tensor[(768, 768), float32] /* ty=Tensor[(768, 768), float32] span=/bert/encoder/layer.11/attention/self/key/MatMul.onnx::MatMul_1731:0:0 */, %onnx::MatMul_1737: Tensor[(768, 768), float32] /* ty=Tensor[(768, 768), float32] span=/bert/encoder/layer.11/attention/self/value/MatMul.onnx::MatMul_1737:0:0 */, %onnx::MatMul_1747: Tensor[(768, 768), float32] /* ty=Tensor[(768, 768), float32] span=/bert/encoder/layer.11/attention/output/dense/MatMul.onnx::MatMul_1747:0:0 */, %onnx::MatMul_1748: Tensor[(768, 3072), float32] /* ty=Tensor[(768, 3072), float32] span=/bert/encoder/layer.11/intermediate/dense/MatMul.onnx::MatMul_1748:0:0 */, %onnx::MatMul_1749: Tensor[(3072, 768), float32] /* ty=Tensor[(3072, 768), float32] span=/bert/encoder/layer.11/output/dense/MatMul.onnx::MatMul_1749:0:0 */, %onnx::MatMul_1750: Tensor[(768, 768), float32] /* ty=Tensor[(768, 768), float32] span=/cls/predictions/transform/dense/MatMul.onnx::MatMul_1750:0:0 */, %onnx::MatMul_1751: Tensor[(768, 30522), float32] /* ty=Tensor[(768, 30522), float32] span=/cls/predictions/decoder/MatMul.onnx::MatMul_1751:0:0 */) -> Tensor[(8, 512, 30522), float32] {

  %34 = reshape(%24, newshape=[-1, 512, 64]) /* ty=Tensor[(96, 512, 64), float32] span=/bert/encoder/layer.0/attention/self/MatMul:0:0 */;
  %35 = transpose(%33, axes=[0, 2, 1]) /* ty=Tensor[(96, 512, 64), float32] span=/bert/encoder/layer.0/attention/self/MatMul:0:0 */;
  %36 = nn.batch_matmul(%34, %35, out_dtype="float32", transpose_b=True) /* ty=Tensor[(96, 512, 512), float32] span=/bert/encoder/layer.0/attention/self/MatMul:0:0 */;

  %48 = reshape(%39, newshape=[-1, 512, 512]) /* ty=Tensor[(96, 512, 512), float32] span=/bert/encoder/layer.0/attention/self/MatMul_1:0:0 */;
  %49 = transpose(%47, axes=[0, 2, 1]) /* ty=Tensor[(96, 64, 512), float32] span=/bert/encoder/layer.0/attention/self/MatMul_1:0:0 */;
  %50 = nn.batch_matmul(%48, %49, out_dtype="float32", transpose_b=True) /* ty=Tensor[(96, 512, 64), float32] span=/bert/encoder/layer.0/attention/self/MatMul_1:0:0 */;

    %111 = reshape(%101, newshape=[-1, 512, 64]) /* ty=Tensor[(96, 512, 64), float32] span=/bert/encoder/layer.1/attention/self/MatMul:0:0 */;
  %112 = transpose(%110, axes=[0, 2, 1]) /* ty=Tensor[(96, 512, 64), float32] span=/bert/encoder/layer.1/attention/self/MatMul:0:0 */;
  %113 = nn.batch_matmul(%111, %112, out_dtype="float32", transpose_b=True) /* ty=Tensor[(96, 512, 512), float32] span=/bert/encoder/layer.1/attention/self/MatMul:0:0 */;

    %125 = reshape(%116, newshape=[-1, 512, 512]) /* ty=Tensor[(96, 512, 512), float32] span=/bert/encoder/layer.1/attention/self/MatMul_1:0:0 */;
  %126 = transpose(%124, axes=[0, 2, 1]) /* ty=Tensor[(96, 64, 512), float32] span=/bert/encoder/layer.1/attention/self/MatMul_1:0:0 */;
  %127 = nn.batch_matmul(%125, %126, out_dtype="float32", transpose_b=True) /* ty=Tensor[(96, 512, 64), float32] span=/bert/encoder/layer.1/attention/self/MatMul_1:0:0 */;

  %188 = reshape(%178, newshape=[-1, 512, 64]) /* ty=Tensor[(96, 512, 64), float32] span=/bert/encoder/layer.2/attention/self/MatMul:0:0 */;
  %189 = transpose(%187, axes=[0, 2, 1]) /* ty=Tensor[(96, 512, 64), float32] span=/bert/encoder/layer.2/attention/self/MatMul:0:0 */;
  %190 = nn.batch_matmul(%188, %189, out_dtype="float32", transpose_b=True) /* ty=Tensor[(96, 512, 512), float32] span=/bert/encoder/layer.2/attention/self/MatMul:0:0 */;

  %202 = reshape(%193, newshape=[-1, 512, 512]) /* ty=Tensor[(96, 512, 512), float32] span=/bert/encoder/layer.2/attention/self/MatMul_1:0:0 */;
  %203 = transpose(%201, axes=[0, 2, 1]) /* ty=Tensor[(96, 64, 512), float32] span=/bert/encoder/layer.2/attention/self/MatMul_1:0:0 */;
  %204 = nn.batch_matmul(%202, %203, out_dtype="float32", transpose_b=True) /* ty=Tensor[(96, 512, 64), float32] span=/bert/encoder/layer.2/attention/self/MatMul_1:0:0 */;

  %265 = reshape(%255, newshape=[-1, 512, 64]) /* ty=Tensor[(96, 512, 64), float32] span=/bert/encoder/layer.3/attention/self/MatMul:0:0 */;
  %266 = transpose(%264, axes=[0, 2, 1]) /* ty=Tensor[(96, 512, 64), float32] span=/bert/encoder/layer.3/attention/self/MatMul:0:0 */;
  %267 = nn.batch_matmul(%265, %266, out_dtype="float32", transpose_b=True) /* ty=Tensor[(96, 512, 512), float32] span=/bert/encoder/layer.3/attention/self/MatMul:0:0 */;

  %279 = reshape(%270, newshape=[-1, 512, 512]) /* ty=Tensor[(96, 512, 512), float32] span=/bert/encoder/layer.3/attention/self/MatMul_1:0:0 */;
  %280 = transpose(%278, axes=[0, 2, 1]) /* ty=Tensor[(96, 64, 512), float32] span=/bert/encoder/layer.3/attention/self/MatMul_1:0:0 */;
  %281 = nn.batch_matmul(%279, %280, out_dtype="float32", transpose_b=True) /* ty=Tensor[(96, 512, 64), float32] span=/bert/encoder/layer.3/attention/self/MatMul_1:0:0 */;

  %342 = reshape(%332, newshape=[-1, 512, 64]) /* ty=Tensor[(96, 512, 64), float32] span=/bert/encoder/layer.4/attention/self/MatMul:0:0 */;
  %343 = transpose(%341, axes=[0, 2, 1]) /* ty=Tensor[(96, 512, 64), float32] span=/bert/encoder/layer.4/attention/self/MatMul:0:0 */;
  %344 = nn.batch_matmul(%342, %343, out_dtype="float32", transpose_b=True) /* ty=Tensor[(96, 512, 512), float32] span=/bert/encoder/layer.4/attention/self/MatMul:0:0 */;

  %356 = reshape(%347, newshape=[-1, 512, 512]) /* ty=Tensor[(96, 512, 512), float32] span=/bert/encoder/layer.4/attention/self/MatMul_1:0:0 */;
  %357 = transpose(%355, axes=[0, 2, 1]) /* ty=Tensor[(96, 64, 512), float32] span=/bert/encoder/layer.4/attention/self/MatMul_1:0:0 */;
  %358 = nn.batch_matmul(%356, %357, out_dtype="float32", transpose_b=True) /* ty=Tensor[(96, 512, 64), float32] span=/bert/encoder/layer.4/attention/self/MatMul_1:0:0 */;

  %419 = reshape(%409, newshape=[-1, 512, 64]) /* ty=Tensor[(96, 512, 64), float32] span=/bert/encoder/layer.5/attention/self/MatMul:0:0 */;
  %420 = transpose(%418, axes=[0, 2, 1]) /* ty=Tensor[(96, 512, 64), float32] span=/bert/encoder/layer.5/attention/self/MatMul:0:0 */;
  %421 = nn.batch_matmul(%419, %420, out_dtype="float32", transpose_b=True) /* ty=Tensor[(96, 512, 512), float32] span=/bert/encoder/layer.5/attention/self/MatMul:0:0 */;

  %433 = reshape(%424, newshape=[-1, 512, 512]) /* ty=Tensor[(96, 512, 512), float32] span=/bert/encoder/layer.5/attention/self/MatMul_1:0:0 */;
  %434 = transpose(%432, axes=[0, 2, 1]) /* ty=Tensor[(96, 64, 512), float32] span=/bert/encoder/layer.5/attention/self/MatMul_1:0:0 */;
  %435 = nn.batch_matmul(%433, %434, out_dtype="float32", transpose_b=True) /* ty=Tensor[(96, 512, 64), float32] span=/bert/encoder/layer.5/attention/self/MatMul_1:0:0 */;

  %496 = reshape(%486, newshape=[-1, 512, 64]) /* ty=Tensor[(96, 512, 64), float32] span=/bert/encoder/layer.6/attention/self/MatMul:0:0 */;
  %497 = transpose(%495, axes=[0, 2, 1]) /* ty=Tensor[(96, 512, 64), float32] span=/bert/encoder/layer.6/attention/self/MatMul:0:0 */;
  %498 = nn.batch_matmul(%496, %497, out_dtype="float32", transpose_b=True) /* ty=Tensor[(96, 512, 512), float32] span=/bert/encoder/layer.6/attention/self/MatMul:0:0 */;

  %510 = reshape(%501, newshape=[-1, 512, 512]) /* ty=Tensor[(96, 512, 512), float32] span=/bert/encoder/layer.6/attention/self/MatMul_1:0:0 */;
  %511 = transpose(%509, axes=[0, 2, 1]) /* ty=Tensor[(96, 64, 512), float32] span=/bert/encoder/layer.6/attention/self/MatMul_1:0:0 */;
  %512 = nn.batch_matmul(%510, %511, out_dtype="float32", transpose_b=True) /* ty=Tensor[(96, 512, 64), float32] span=/bert/encoder/layer.6/attention/self/MatMul_1:0:0 */;

  %573 = reshape(%563, newshape=[-1, 512, 64]) /* ty=Tensor[(96, 512, 64), float32] span=/bert/encoder/layer.7/attention/self/MatMul:0:0 */;
  %574 = transpose(%572, axes=[0, 2, 1]) /* ty=Tensor[(96, 512, 64), float32] span=/bert/encoder/layer.7/attention/self/MatMul:0:0 */;
  %575 = nn.batch_matmul(%573, %574, out_dtype="float32", transpose_b=True) /* ty=Tensor[(96, 512, 512), float32] span=/bert/encoder/layer.7/attention/self/MatMul:0:0 */;

  %587 = reshape(%578, newshape=[-1, 512, 512]) /* ty=Tensor[(96, 512, 512), float32] span=/bert/encoder/layer.7/attention/self/MatMul_1:0:0 */;
  %588 = transpose(%586, axes=[0, 2, 1]) /* ty=Tensor[(96, 64, 512), float32] span=/bert/encoder/layer.7/attention/self/MatMul_1:0:0 */;
  %589 = nn.batch_matmul(%587, %588, out_dtype="float32", transpose_b=True) /* ty=Tensor[(96, 512, 64), float32] span=/bert/encoder/layer.7/attention/self/MatMul_1:0:0 */;

  %650 = reshape(%640, newshape=[-1, 512, 64]) /* ty=Tensor[(96, 512, 64), float32] span=/bert/encoder/layer.8/attention/self/MatMul:0:0 */;
  %651 = transpose(%649, axes=[0, 2, 1]) /* ty=Tensor[(96, 512, 64), float32] span=/bert/encoder/layer.8/attention/self/MatMul:0:0 */;
  %652 = nn.batch_matmul(%650, %651, out_dtype="float32", transpose_b=True) /* ty=Tensor[(96, 512, 512), float32] span=/bert/encoder/layer.8/attention/self/MatMul:0:0 */;

  %664 = reshape(%655, newshape=[-1, 512, 512]) /* ty=Tensor[(96, 512, 512), float32] span=/bert/encoder/layer.8/attention/self/MatMul_1:0:0 */;
  %665 = transpose(%663, axes=[0, 2, 1]) /* ty=Tensor[(96, 64, 512), float32] span=/bert/encoder/layer.8/attention/self/MatMul_1:0:0 */;
  %666 = nn.batch_matmul(%664, %665, out_dtype="float32", transpose_b=True) /* ty=Tensor[(96, 512, 64), float32] span=/bert/encoder/layer.8/attention/self/MatMul_1:0:0 */;

  %727 = reshape(%717, newshape=[-1, 512, 64]) /* ty=Tensor[(96, 512, 64), float32] span=/bert/encoder/layer.9/attention/self/MatMul:0:0 */;
  %728 = transpose(%726, axes=[0, 2, 1]) /* ty=Tensor[(96, 512, 64), float32] span=/bert/encoder/layer.9/attention/self/MatMul:0:0 */;
  %729 = nn.batch_matmul(%727, %728, out_dtype="float32", transpose_b=True) /* ty=Tensor[(96, 512, 512), float32] span=/bert/encoder/layer.9/attention/self/MatMul:0:0 */;

  %741 = reshape(%732, newshape=[-1, 512, 512]) /* ty=Tensor[(96, 512, 512), float32] span=/bert/encoder/layer.9/attention/self/MatMul_1:0:0 */;
  %742 = transpose(%740, axes=[0, 2, 1]) /* ty=Tensor[(96, 64, 512), float32] span=/bert/encoder/layer.9/attention/self/MatMul_1:0:0 */;
  %743 = nn.batch_matmul(%741, %742, out_dtype="float32", transpose_b=True) /* ty=Tensor[(96, 512, 64), float32] span=/bert/encoder/layer.9/attention/self/MatMul_1:0:0 */;

  %804 = reshape(%794, newshape=[-1, 512, 64]) /* ty=Tensor[(96, 512, 64), float32] span=/bert/encoder/layer.10/attention/self/MatMul:0:0 */;
  %805 = transpose(%803, axes=[0, 2, 1]) /* ty=Tensor[(96, 512, 64), float32] span=/bert/encoder/layer.10/attention/self/MatMul:0:0 */;
  %806 = nn.batch_matmul(%804, %805, out_dtype="float32", transpose_b=True) /* ty=Tensor[(96, 512, 512), float32] span=/bert/encoder/layer.10/attention/self/MatMul:0:0 */;

  %818 = reshape(%809, newshape=[-1, 512, 512]) /* ty=Tensor[(96, 512, 512), float32] span=/bert/encoder/layer.10/attention/self/MatMul_1:0:0 */;
  %819 = transpose(%817, axes=[0, 2, 1]) /* ty=Tensor[(96, 64, 512), float32] span=/bert/encoder/layer.10/attention/self/MatMul_1:0:0 */;
  %820 = nn.batch_matmul(%818, %819, out_dtype="float32", transpose_b=True) /* ty=Tensor[(96, 512, 64), float32] span=/bert/encoder/layer.10/attention/self/MatMul_1:0:0 */;

  %881 = reshape(%871, newshape=[-1, 512, 64]) /* ty=Tensor[(96, 512, 64), float32] span=/bert/encoder/layer.11/attention/self/MatMul:0:0 */;
  %882 = transpose(%880, axes=[0, 2, 1]) /* ty=Tensor[(96, 512, 64), float32] span=/bert/encoder/layer.11/attention/self/MatMul:0:0 */;
  %883 = nn.batch_matmul(%881, %882, out_dtype="float32", transpose_b=True) /* ty=Tensor[(96, 512, 512), float32] span=/bert/encoder/layer.11/attention/self/MatMul:0:0 */;

  %895 = reshape(%886, newshape=[-1, 512, 512]) /* ty=Tensor[(96, 512, 512), float32] span=/bert/encoder/layer.11/attention/self/MatMul_1:0:0 */;
  %896 = transpose(%894, axes=[0, 2, 1]) /* ty=Tensor[(96, 64, 512), float32] span=/bert/encoder/layer.11/attention/self/MatMul_1:0:0 */;
  %897 = nn.batch_matmul(%895, %896, out_dtype="float32", transpose_b=True) /* ty=Tensor[(96, 512, 64), float32] span=/bert/encoder/layer.11/attention/self/MatMul_1:0:0 */;

